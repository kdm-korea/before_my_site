---
layout: post
title:  "[Tensorflow]2.Linear Rigression"
date:   2017-08-04 11:59:00 -0500
comments: true
categories: tensorflow
---

## Linear Rigression

<br>
이번 시간에는 tensorflow를 이용하여 머신러닝(기계학습)을 구현하는 방법을 간단하게 설명하고 간단한 예제 실행도 해보겠습니다.
<br>
[0.tensorflow는 무엇인가?](http://kookyungmin.github.io/tensorflow/2017/08/03/tensorflow01.html) 에서 간단하게 설명했었지만
<br>
머신러닝은 훈련 데이터들을 이용하여 데이터를 구분지을 수 있는 판별식(WX+b)를 구한 후 새로운 데이터를 예측하는 방법이라고 하였습니다.
<br>
말로 설명하면 아직 감이 안 오시는 분들이 많죠~ 직접 예제를 실행해보면서 알아가는 시간을 갖겠습니다.
<br>
<br>
머신러닝은 크게 4단계로 이뤄진다고 보면 됩니다.
<br>
1.train data를 준비한다.
<br>
2.Hypothesis(판별식)을 설정한다.
<br>
3.Cost함수를 설정한다.
<br>
4.cost함수를 최소화시키는 W,b를 구한다.
<br>

## 1.Train data set을 준비한다.
<br>

>여기서 Train set이라고 하면 x_data(속성 값), y_data(실제 값)을 말합니다.
><br>
>예를 들어 어떤 사람의 국어 영어 수학 등급을 입력하여 어느 대학교 합격,불합격 여부를 알고 싶다고 합시다.
><br>
>그러면 학습을 하기 위해서 실제 데이터들이 필요한데, 학습데이터는 다음과 같은 형태입니다.
><br>
>
>```python
>x_data={1,2,1} //국어 영어 수학 등급
>y_data={1} //0:불합격 1:합격
>```

<br>

## 2.Hypothesis(판별식)을 설정한다.
<br>

>여기서 Hypothesis는 데이터들을 구분할 수 있는 직선 정도라고 생각하면 됩니다. 
><br>
>
>```python
>hypothesis=WX+b
>```
>
<br>

## 3.Cost함수를 설정한다.
<br>
>cost 함수는 우리가 hypothesis로 설정한 직선으로 구한 예측 값과 실제 값이 얼마나 다른가를 나타내는 함수정도로 생각하면 됩니다.
><br>
cost함수를 일단 다음과 같이 정의하겠습니다.
<br>

<img src = " http://latex.codecogs.com/ svg .latex? cost(W,b)={1\over m}\sum\limits_{i=1}^{m}(H(x_i)-y_i)^2 "border = "0"/> 

<br>

$$$ H(x_i):예측데이터 $$$ 

$$$ y_i:실제데이터 $$$ 

<br>

>```python
>cost=tf.reduce_mean(tf.square(hypothesis-Y))
>```
>
><br>
>tf.reduce_mean는 평균을 구해주고, 
>tf.square는 제곱을 해준다.

<br>

## 4.cost함수를 최소화시키는 W,b를 구한다.

<br>

>컴퓨터는 데이터를 훈련시키면서 cost 함수(우리가 예측한 값과 실제 값의 차이)를 작게 하는 W와 b 값을 구합니다.
><br>
>W,b를 구하는 법은 Gradient decent algorithm(경사감소법)을 이용하는데 구체적인 방법은 알지 못해도 좋아요.
><br>
>왜냐하면 컴퓨터가 알아서 하기 때문이죠!!!!
><br> 
>심지어 W,b도 컴퓨터가 스스로 변경한답니다!!
